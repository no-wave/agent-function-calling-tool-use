{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCP와 OpenAI 통합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 흐름 설명\n",
    "\n",
    "1. **사용자 질문**: 사용자가 시스템에 질문을 보낸다 (예: \"우리 회사의 휴가 정책은 무엇인가?\").\n",
    "2. **OpenAI API**: OpenAI는 MCP 서버로부터 받은 사용 가능한 도구와 함께 질문을 받는다.\n",
    "3. **도구 선택**: OpenAI는 질문에 기반하여 어떤 도구를 사용할지 결정한다.\n",
    "4. **MCP 클라이언트**: 클라이언트는 OpenAI의 도구 호출 요청을 받아 MCP 서버로 전달한다.\n",
    "5. **MCP 서버**: 서버는 요청된 도구를 실행한다 (예: 지식 베이스 데이터 검색).\n",
    "6. **응답 흐름**: 도구 결과는 MCP 클라이언트를 통해 OpenAI로 다시 전달된다.\n",
    "7. **최종 응답**: OpenAI는 도구 데이터를 통합하여 최종 응답을 생성한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 지식 베이스 (Knowledge Base) 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# 데이터 디렉토리 생성\n",
    "if not os.path.exists('data'):\n",
    "    os.makedirs('data')\n",
    "\n",
    "# 지식 베이스 데이터 정의\n",
    "kb_data = [\n",
    "    {\n",
    "        \"question\": \"What is the company's vacation policy?\",\n",
    "        \"answer\": \"Employees are entitled to 20 paid vacation days per year. Unused days can be carried over up to a maximum of 5 days to the next year.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What are the working hours?\",\n",
    "        \"answer\": \"Standard working hours are from 9:00 AM to 6:00 PM, Monday to Friday, with a one-hour lunch break.\"\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How does the remote work policy work?\",\n",
    "        \"answer\": \"Employees can work remotely up to 2 days per week with approval from their direct manager.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# kb.json 파일 작성\n",
    "with open('data/kb.json', 'w') as f:\n",
    "    json.dump(kb_data, f, indent=2)\n",
    "\n",
    "print(\"'data/kb.json' 파일이 성공적으로 생성되었다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 서버 (`server.py`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile server.py\n",
    "import os\n",
    "import json\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "\n",
    "# MCP 서버 생성\n",
    "mcp = FastMCP(\n",
    "    name=\"Knowledge Base\",\n",
    "    host=\"0.0.0.0\",  # SSE 전송 방식에서만 사용됨 (localhost)\n",
    "    port=8050,  # SSE 전송 방식에서만 사용됨 (원하는 포트로 설정)\n",
    ")\n",
    "\n",
    "\n",
    "@mcp.tool()\n",
    "def get_knowledge_base() -> str:\n",
    "    \"\"\"전체 지식 베이스를 형식화된 문자열로 검색한다.\n",
    "\n",
    "    Returns:\n",
    "        지식 베이스의 모든 Q&A 쌍을 포함하는 형식화된 문자열이다.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        kb_path = os.path.join(os.path.dirname(__file__), \"data\", \"kb.json\")\n",
    "        with open(kb_path, \"r\") as f:\n",
    "            kb_data = json.load(f)\n",
    "\n",
    "        # 지식 베이스를 문자열로 형식화\n",
    "        kb_text = \"검색된 지식 베이스는 다음과 같다:\\n\\n\"\n",
    "\n",
    "        if isinstance(kb_data, list):\n",
    "            for i, item in enumerate(kb_data, 1):\n",
    "                if isinstance(item, dict):\n",
    "                    question = item.get(\"question\", \"알 수 없는 질문\")\n",
    "                    answer = item.get(\"answer\", \"알 수 없는 답변\")\n",
    "                else:\n",
    "                    question = f\"항목 {i}\"\n",
    "                    answer = str(item)\n",
    "\n",
    "                kb_text += f\"Q{i}: {question}\\n\"\n",
    "                kb_text += f\"A{i}: {answer}\\n\\n\"\n",
    "        else:\n",
    "            kb_text += f\"지식 베이스 내용: {json.dumps(kb_data, indent=2)}\\n\\n\"\n",
    "\n",
    "        return kb_text\n",
    "    except FileNotFoundError:\n",
    "        return \"오류: 지식 베이스 파일을 찾을 수 없다\"\n",
    "    except json.JSONDecodeError:\n",
    "        return \"오류: 지식 베이스 파일에 잘못된 JSON이 있다\"\n",
    "    except Exception as e:\n",
    "        return f\"오류: {str(e)}\"\n",
    "\n",
    "\n",
    "# 서버 실행\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport=\"stdio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 클라이언트 (`client.py`)\n",
    "\n",
    "클라이언트는 다음을 수행한다:\n",
    "1. MCP 서버에 연결한다.\n",
    "2. MCP 도구를 OpenAI의 함수 형식으로 변환한다.\n",
    "3. OpenAI와 MCP 서버 간의 통신을 처리한다.\n",
    "4. 도구 결과를 처리하고 최종 응답을 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "from contextlib import AsyncExitStack\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import nest_asyncio\n",
    "from dotenv import load_dotenv\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "# 중첩 이벤트 루프를 허용하도록 nest_asyncio 적용 (Jupyter/IPython에 필요)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# .env 파일에서 환경 변수 로드 (OPENAI_API_KEY 설정 필요)\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "class MCPOpenAIClient:\n",
    "    \"\"\"MCP 도구를 사용하여 OpenAI 모델과 상호 작용하는 클라이언트다.\"\"\"\n",
    "\n",
    "    def __init__(self, model: str = \"gpt-4o\"):\n",
    "        \"\"\"OpenAI MCP 클라이언트를 초기화한다.\n",
    "\n",
    "        Args:\n",
    "            model: 사용할 OpenAI 모델이다.\n",
    "        \"\"\"\n",
    "        # 세션 및 클라이언트 객체 초기화\n",
    "        self.session: Optional[ClientSession] = None\n",
    "        self.exit_stack = AsyncExitStack()\n",
    "        self.openai_client = AsyncOpenAI()\n",
    "        self.model = model\n",
    "        self.stdio: Optional[Any] = None\n",
    "        self.write: Optional[Any] = None\n",
    "\n",
    "    async def connect_to_server(self, server_script_path: str = \"server.py\"):\n",
    "        \"\"\"MCP 서버에 연결한다.\n",
    "\n",
    "        Args:\n",
    "            server_script_path: 서버 스크립트의 경로다.\n",
    "        \"\"\"\n",
    "        # 서버 설정\n",
    "        server_params = StdioServerParameters(\n",
    "            command=\"python\",\n",
    "            args=[server_script_path],\n",
    "        )\n",
    "\n",
    "        # 서버에 연결\n",
    "        stdio_transport = await self.exit_stack.enter_async_context(\n",
    "            stdio_client(server_params)\n",
    "        )\n",
    "        self.stdio, self.write = stdio_transport\n",
    "        self.session = await self.exit_stack.enter_async_context(\n",
    "            ClientSession(self.stdio, self.write)\n",
    "        )\n",
    "\n",
    "        # 연결 초기화\n",
    "        await self.session.initialize()\n",
    "\n",
    "        # 사용 가능한 도구 목록 출력\n",
    "        tools_result = await self.session.list_tools()\n",
    "        print(\"\\n서버에 연결되었으며 사용 가능한 도구는 다음과 같다:\")\n",
    "        for tool in tools_result.tools:\n",
    "            print(f\"  - {tool.name}: {tool.description}\")\n",
    "\n",
    "    async def get_mcp_tools(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"MCP 서버에서 사용 가능한 도구를 OpenAI 형식으로 가져온다.\n",
    "\n",
    "        Returns:\n",
    "            OpenAI 형식의 도구 목록이다.\n",
    "        \"\"\"\n",
    "        tools_result = await self.session.list_tools()\n",
    "        return [\n",
    "            {\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": tool.name,\n",
    "                    \"description\": tool.description,\n",
    "                    \"parameters\": tool.inputSchema,\n",
    "                },\n",
    "            }\n",
    "            for tool in tools_result.tools\n",
    "        ]\n",
    "\n",
    "    async def process_query(self, query: str) -> str:\n",
    "        \"\"\"OpenAI와 사용 가능한 MCP 도구를 사용하여 질문을 처리한다.\n",
    "\n",
    "        Args:\n",
    "            query: 사용자 질문이다.\n",
    "\n",
    "        Returns:\n",
    "            OpenAI의 응답이다.\n",
    "        \"\"\"\n",
    "        # 사용 가능한 도구 가져오기\n",
    "        tools = await self.get_mcp_tools()\n",
    "\n",
    "        # 초기 OpenAI API 호출\n",
    "        response = await self.openai_client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": query}],\n",
    "            tools=tools,\n",
    "            tool_choice=\"auto\",\n",
    "        )\n",
    "\n",
    "        # 어시스턴트의 응답 가져오기\n",
    "        assistant_message = response.choices[0].message\n",
    "\n",
    "        # 사용자 질문과 어시스턴트 응답으로 대화 초기화\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": query},\n",
    "            assistant_message,\n",
    "        ]\n",
    "\n",
    "        # 도구 호출이 있는 경우 처리\n",
    "        if assistant_message.tool_calls:\n",
    "            # 각 도구 호출 처리\n",
    "            for tool_call in assistant_message.tool_calls:\n",
    "                # 도구 호출 실행\n",
    "                result = await self.session.call_tool(\n",
    "                    tool_call.function.name,\n",
    "                    arguments=json.loads(tool_call.function.arguments),\n",
    "                )\n",
    "\n",
    "                # 대화에 도구 응답 추가\n",
    "                messages.append(\n",
    "                    {\n",
    "                        \"role\": \"tool\",\n",
    "                        \"tool_call_id\": tool_call.id,\n",
    "                        \"content\": result.content[0].text,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            # 도구 결과를 포함하여 OpenAI에서 최종 응답 가져오기\n",
    "            final_response = await self.openai_client.chat.completions.create(\n",
    "                model=self.model,\n",
    "                messages=messages,\n",
    "                tools=tools,\n",
    "                tool_choice=\"none\",  # 더 이상의 도구 호출 비허용\n",
    "            )\n",
    "\n",
    "            return final_response.choices[0].message.content\n",
    "\n",
    "        # 도구 호출이 없으면 직접 응답 반환\n",
    "        return assistant_message.content\n",
    "\n",
    "    async def cleanup(self):\n",
    "        \"\"\"자원을 정리한다.\"\"\"\n",
    "        await self.exit_stack.aclose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제 실행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_example():\n",
    "    \"\"\"예제를 실행하는 메인 진입점이다.\"\"\"\n",
    "    client = MCPOpenAIClient()\n",
    "    await client.connect_to_server(\"server.py\")\n",
    "\n",
    "    # 예제: 회사 휴가 정책에 대해 질문\n",
    "    query = \"What is our company's vacation policy?\"\n",
    "    print(f\"\\n질문: {query}\")\n",
    "\n",
    "    response = await client.process_query(query)\n",
    "    print(f\"\\n응답: {response}\")\n",
    "    \n",
    "    # 자원 정리\n",
    "    await client.cleanup()\n",
    "\n",
    "# 비동기 함수 실행\n",
    "await run_example()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
