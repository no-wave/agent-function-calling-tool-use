{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ld7qJvLKoKD4"
   },
   "source": [
    "# Structured Output: 구조화된 출력과 함수 호출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ld7qJvLKoKD4"
   },
   "source": [
    "## LLM 기반 시스템\n",
    "\n",
    "1.  구조화된 출력을 사용하여 자연어에서 구조화된 데이터를 파싱한다.\n",
    "2.  함수 호출을 사용하여 주가에 대한 Q\\&A 시스템을 구축한다.\n",
    "\n",
    "  * **구조화된 출력** 파인튜닝은 모델이 JSON을 더 안정적으로 출력하게 해준다.\n",
    "  * **함수 호출**은 추가적인 단계를 거치는 구조화된 출력으로, 사실상 RAG(검색 증강 생성)처럼 작동한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ld7qJvLKoKD4"
   },
   "source": [
    "## 구조화된 출력과 함수호출이 필요한 이유\n",
    "\n",
    "1.  모델이 모든 데이터를 가지고 있지 않다.\n",
    "2.  모델을 다른 시스템과 통합해야 한다.\n",
    "3.  LLM 아키텍처 자체에 몇 가지 한계가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ld7qJvLKoKD4"
   },
   "source": [
    "## 사용 사례"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv  \n",
    "\n",
    "!echo \"OPENAI_API_KEY=<OpenAI Key를 여기에 붙혀넣기 하세요.\" >> .env\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 모델을 정의한다.\n",
    "MODEL = \"gpt-4.1-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "YyOqHq-MoKD7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "# 헬퍼 함수\n",
    "def eval(prompt: str, message: str, model: str = \"gpt-4.1-mini\") -> str:\n",
    "    client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ]\n",
    "\n",
    "    # JSON 모드를 활성화한다\n",
    "    response_format = {\"type\": \"json_object\"}\n",
    "\n",
    "    res = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        response_format=response_format\n",
    "    )\n",
    "    return res.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "MFYZLhtWoKD9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력: \"빵 좀 사고, 계란 한 팩, 사과 몇 개, 그리고 우유 한 병 사고 싶어요.\"\n",
      "{\n",
      "    \"groceries\": [\n",
      "        { \"name\": \"빵\", \"quantity\": 1 },\n",
      "        { \"name\": \"계란\", \"quantity\": 1 },\n",
      "        { \"name\": \"사과\", \"quantity\": 3 },\n",
      "        { \"name\": \"우유\", \"quantity\": 1 }\n",
      "    ]\n",
      "}\n",
      "--------------------\n",
      "입력: \"계란 12개, 우유 2병, 탄산수 6개\"\n",
      "{\n",
      "    \"groceries\": [\n",
      "        { \"name\": \"계란\", \"quantity\": 12 },\n",
      "        { \"name\": \"우유\", \"quantity\": 2 },\n",
      "        { \"name\": \"탄산수\", \"quantity\": 6 }\n",
      "    ]\n",
      "}\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# 프롬프트: JSON 스키마를 명시하여 LLM에 지시한다.\n",
    "prompt = \"\"\"\n",
    "당신은 데이터 파싱 어시스턴트입니다.\n",
    "사용자가 식료품 목록을 제공합니다.\n",
    "다음 JSON 스키마를 사용하여 응답을 생성하세요:\n",
    "\n",
    "{{\n",
    "    \"groceries\": [\n",
    "        {{ \"name\": ITEM_NAME, \"quantity\": ITEM_QUANTITY }}\n",
    "    ]\n",
    "}}\n",
    "\n",
    "이름(name)은 모든 문자열이며, 수량(quantity)은 숫자 값입니다.\n",
    "\"\"\"\n",
    "\n",
    "# 사용자 입력\n",
    "inputs = [\n",
    "    \"빵 좀 사고, 계란 한 팩, 사과 몇 개, 그리고 우유 한 병 사고 싶어요.\",\n",
    "    \"계란 12개, 우유 2병, 탄산수 6개\",\n",
    "]\n",
    "\n",
    "for message in inputs:\n",
    "    json_data = eval(prompt=prompt, message=message)\n",
    "    print(f\"입력: \\\"{message}\\\"\")\n",
    "    print(json_data)\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4ntFvoSoKD9"
   },
   "source": [
    "이제 정의된 스키마에 따라 일관된 출력을 얻었다. 사용자 입력은 LLM 출력에 영향을 미치므로, 가능한 한 많은 테스트를 작성하여 정확성을 보장하고 회귀를 방지하는 것이 매우 중요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4ntFvoSoKD9"
   },
   "source": [
    "## 함수 호출의 작동 방식\n",
    "\n",
    "함수 호출은 구조화된 출력과 동일한 메커니즘에 몇 가지 추가 단계가 더해진 것이다. LLM은 단순한 JSON 대신, 미리 정의된 스키마에서 함수 이름과 그 매개변수를 반환한다.\n",
    "\n",
    "**워크플로우:**\n",
    "\n",
    "1.  사용 가능한 함수에 대한 설명을 LLM에 제공한다.\n",
    "2.  LLM이 그중 하나가 필요하다고 판단하면, **선택된 함수**를 호출해 달라는 요청을 반환한다.\n",
    "3.  **당신이(당신의 코드가)** LLM이 요청한 함수를 호출한다.\n",
    "4.  함수의 반환 값을 다시 LLM에 제공한다.\n",
    "5.  LLM이 최종 답변을 생성한다.\n",
    "\n",
    "본질적으로, 당신은 LLM에 어떤 데이터 명세를 제공하는 것이다. 함수 호출 API 없이 구조화된 출력만으로도 함수 호출을 구현할 수 있지만, 깔끔하지는 않을 것이다. 함수 호출은 구조화된 출력의 특화된 사용 사례일 뿐이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4ntFvoSoKD9"
   },
   "source": [
    "## 코드로 구현하기\n",
    "\n",
    "전체 로직을 `controller` 함수에 담아 구현한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5ksFRmZXoKD-",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오늘 다우 존스 산업평균지수(DJI)의 가격은 40,345.41입니다.\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from typing import List, Callable, Dict\n",
    "\n",
    "# 전역 변수 설정\n",
    "MODEL = \"gpt-4.1-mini\"\n",
    "client = OpenAI()\n",
    "\n",
    "def get_prompt() -> str:\n",
    "    \"\"\"시스템 프롬프트를 반환한다.\"\"\"\n",
    "    return \"당신은 유용한 어시스턴트입니다. 응답이 명확하지 않을 경우 제공된 함수를 사용하세요.\"\n",
    "\n",
    "def get_stock_price(ticker: str) -> str:\n",
    "    \"\"\"주어진 티커의 주가를 반환하는 모의 함수다.\"\"\"\n",
    "    local_data = {\"DJI\": \"40,345.41\", \"MSFT\": \"421.53\", \"AAPL\": \"225.89\"}\n",
    "    # 실제 운영 환경에서는 키 존재 여부를 확인해야 한다.\n",
    "    return local_data.get(ticker, \"해당 티커를 찾을 수 없습니다.\")\n",
    "\n",
    "def get_llm_functions() -> List[Dict]:\n",
    "    \"\"\"LLM에 제공할 함수 정의(스키마) 목록을 반환한다.\"\"\"\n",
    "    return [\n",
    "        {\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "                \"name\": \"get_stock_price\",\n",
    "                \"description\": \"현재 주가 지수 가격을 가져옵니다.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"ticker\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"TICKER 형식의 주가 지수 티커, ^나 $ 같은 접두사 없음\",\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"ticker\"],\n",
    "                },\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "\n",
    "def get_completion(messages: List[Dict], tools=None):\n",
    "    \"\"\"LLM API를 호출하는 헬퍼 함수다.\"\"\"\n",
    "    return client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        tools=tools # 'tools'에 함수 정의를 전달한다.\n",
    "    )\n",
    "\n",
    "def controller(user_input: str, functions: Dict[str, Callable]) -> str:\n",
    "    \"\"\"함수 호출 로직을 실행하는 메인 컨트롤러다.\"\"\"\n",
    "    prompt = get_prompt()\n",
    "    llm_functions = get_llm_functions()\n",
    "\n",
    "    # 첫 번째 대화 메시지를 설정한다.\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt},\n",
    "        {\"role\": \"user\", \"content\": user_input},\n",
    "    ]\n",
    "\n",
    "    # 함수 목록과 함께 첫 번째 LLM 응답을 생성한다.\n",
    "    completion = get_completion(messages=messages, tools=llm_functions)\n",
    "    response_message = completion.choices[0].message\n",
    "\n",
    "    # LLM이 도구(함수) 호출을 요청했는지 확인한다.\n",
    "    if response_message.tool_calls:\n",
    "        # tool_calls 목록의 첫 번째 요청을 가져온다.\n",
    "        tool_call = response_message.tool_calls[0]\n",
    "        function_name = tool_call.function.name\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "        # 실제 파이썬 함수를 호출한다.\n",
    "        function_to_call = functions[function_name]\n",
    "        function_response = function_to_call(**function_args)\n",
    "\n",
    "        # 대화 기록에 어시스턴트의 함수 호출 요청과\n",
    "        # 실제 함수 실행 결과를 추가한다.\n",
    "        messages.append(response_message)  # 어시스턴트의 응답\n",
    "        messages.append(\n",
    "            {\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"role\": \"tool\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # 업데이트된 대화 기록으로 다시 LLM을 호출하여 최종 답변을 얻는다.\n",
    "        second_completion = get_completion(messages=messages)\n",
    "        return second_completion.choices[0].message.content\n",
    "\n",
    "    # 함수 호출이 필요 없는 경우, 첫 번째 응답을 바로 반환한다.\n",
    "    return response_message.content\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 사용 가능한 함수를 맵으로 만든다.\n",
    "    available_functions = {\"get_stock_price\": get_stock_price}\n",
    "    # 컨트롤러를 실행하고 결과를 출력한다.\n",
    "    final_response = controller(\n",
    "        \"오늘 다우 존스 가격은 얼마인가요?\",\n",
    "        functions=available_functions,\n",
    "    )\n",
    "    print(final_response)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "lecture",
   "language": "python",
   "name": "lecture"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
