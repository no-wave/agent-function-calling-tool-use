{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EA5m_gvokIaT"
   },
   "source": [
    "# Embedded Calling\n",
    "\n",
    "  * **향상된 개발자 경험**: 개발자는 도구의 실제 로직(예: `get_weather` 함수) 구현에만 집중하면 된다. 도구 호출과 관련된 복잡한 파이프라인은 프레임워크가 추상화하여 처리하므로 개발 생산성이 크게 향상된다.\n",
    "  * **효율성 및 성능 개선**: 도구 실행을 관리하는 중간 계층이 LLM과의 통신을 최적화하고, LLM 추론과 도구 코드가 물리적으로 가까운 곳에서 실행될 경우 네트워크 지연이 최소화되어 매우 빠른 응답이 가능하다.\n",
    "  * **안정성 및 단순성**: 프레임워크가 도구 호출을 직접 처리하므로 LLM의 환각으로 인한 잘못된 함수 호출 가능성이 원천적으로 차단된다. 또한 클라이언트 애플리케이션의 코드가 매우 단순해진다.\n",
    "  * **복잡한 워크플로우 처리 용이**: 여러 도구를 순차적 또는 재귀적으로 호출해야 하는 복잡한 작업도 중간 계층 라이브러리가 상태를 관리하며 처리할 수 있어 확장성이 뛰어나다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv  \n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "MODEL=\"gpt-4.1-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EA5m_gvokIaT"
   },
   "source": [
    "## 일반적인 Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "rib36cPpkIaV",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# 날씨 정보를 가져오는 함수다.\n",
    "def get_weather(city):\n",
    "    api_key = GOOGLE_WEATHER_API_KEY  \n",
    "    api_url = f\"https://api.weatherapi.com/v1/current.json?key={api_key}&q={city}\"\n",
    "    try:\n",
    "        response = requests.get(api_url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        return data['current']['temp_f']\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"날씨 데이터를 가져오는 중 오류가 발생했다: {str(e)}\"\n",
    "\n",
    "# 클라이언트 측에서 도구를 직접 실행하는 함수다.\n",
    "def execute_tool(tool_name, arguments):\n",
    "    if tool_name == \"weather_api\":\n",
    "        args = json.loads(arguments)\n",
    "        return get_weather(args[\"city\"])\n",
    "    return \"알 수 없는 도구다.\"\n",
    "\n",
    "# Traditional Calling의 전체 흐름을 관리하는 클래스다.\n",
    "class TraditionalToolCaller:\n",
    "    def __init__(self, api_key):\n",
    "        self.client = openai.OpenAI(api_key=api_key)\n",
    "\n",
    "    def process_message(self, user_message):\n",
    "        # 1단계: LLM에 메시지와 도구 명세를 보내 도구 사용을 추천받는다.\n",
    "        initial_response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\": user_message}],\n",
    "            tools=[{\n",
    "                \"type\": \"function\",\n",
    "                \"function\": {\n",
    "                    \"name\": \"weather_api\",\n",
    "                    \"description\": \"특정 도시의 좌표값을 읽고 현재 온도를 화씨로 알려준다.\",\n",
    "                    \"parameters\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\"city\": {\"type\": \"string\", \"description\": \"도시 이름\"}},\n",
    "                        \"required\": [\"city\"]\n",
    "                    }\n",
    "                }\n",
    "            }]\n",
    "        )\n",
    "        message = initial_response.choices[0].message\n",
    "\n",
    "        # 2단계: LLM의 추천에 따라 클라이언트가 직접 도구를 실행한다.\n",
    "        if message.tool_calls:\n",
    "            tool_call = message.tool_calls[0]\n",
    "            tool_name = tool_call.function.name\n",
    "            arguments = tool_call.function.arguments\n",
    "            tool_response = execute_tool(tool_name, arguments)\n",
    "\n",
    "            # 3단계: 도구 실행 결과를 다시 LLM에 보내 최종 답변을 생성하도록 요청한다.\n",
    "            final_response = self.client.chat.completions.create(\n",
    "                model=MODEL,\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": user_message},\n",
    "                    message,\n",
    "                    {\"role\": \"tool\", \"tool_call_id\": tool_call.id, \"name\": tool_name, \"content\": str(tool_response)}\n",
    "                ]\n",
    "            )\n",
    "            return final_response.choices[0].message.content\n",
    "        return message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "rib36cPpkIaV",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 마이애미의 온도를 바로 확인할 수 있는 권한이 없습니다. 최신 기상 정보를 확인하시려면 기상청 웹사이트나 날씨 앱을 참고해 주세요.\n"
     ]
    }
   ],
   "source": [
    "tool_caller = TraditionalToolCaller(api_key)\n",
    "result = tool_caller.process_message(\"마이애미의 현재 온도는 몇 도인가요?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "smiyT1DBkIaW"
   },
   "source": [
    "## Embedded Function Calling 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "kmdR7kWrkIaW",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# 날씨 정보를 가져오는 함수는 동일하다.\n",
    "def get_weather(city):\n",
    "    api_key = \"YOUR_WEATHER_API_KEY\"  # 실제 API 키로 교체해야 한다.\n",
    "    api_url = f\"https://api.weatherapi.com/v1/current.json?key={api_key}&q={city}\"\n",
    "    try:\n",
    "        response = requests.get(api_url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        return data['current']['temp_f']\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"날씨 데이터를 가져오는 중 오류가 발생했다: {str(e)}\"\n",
    "\n",
    "# 도구를 관리하고 실행하는 라이브러리 역할의 클래스다.\n",
    "class ToolLibrary:\n",
    "    def __init__(self):\n",
    "        self.tools = {\n",
    "            \"weather_api\": {\n",
    "                \"function\": get_weather,\n",
    "                \"description\": \"특정 도시의 현재 온도를 화씨로 알려준다.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\"city\": {\"type\": \"string\", \"description\": \"도시 이름\"}},\n",
    "                    \"required\": [\"city\"]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def get_tool_definition(self, tool_name):\n",
    "        tool = self.tools.get(tool_name)\n",
    "        if tool:\n",
    "            return {\"type\": \"function\", \"function\": {\"name\": tool_name, \"description\": tool[\"description\"], \"parameters\": tool[\"parameters\"]}}\n",
    "        return None\n",
    "\n",
    "    def execute_tool(self, tool_name, arguments):\n",
    "        tool = self.tools.get(tool_name)\n",
    "        if tool:\n",
    "            args = json.loads(arguments)\n",
    "            return tool[\"function\"](args[\"city\"])\n",
    "        return \"알 수 없는 도구다.\"\n",
    "\n",
    "# Embedded Calling의 전체 흐름을 관리하는 클래스다.\n",
    "class EmbeddedToolCaller:\n",
    "    def __init__(self, api_key):\n",
    "        self.client = openai.OpenAI(api_key=api_key)\n",
    "        self.tool_library = ToolLibrary()\n",
    "\n",
    "    def process_message(self, user_message):\n",
    "        # 1-2단계: 중간 라이브러리가 도구 명세와 함께 LLM에 메시지를 보낸다.\n",
    "        tool_definitions = [self.tool_library.get_tool_definition(\"weather_api\")]\n",
    "        initial_response = self.client.chat.completions.create(\n",
    "            model=MODEL\n",
    "            messages=[{\"role\": \"user\", \"content\": user_message}],\n",
    "            tools=tool_definitions\n",
    "        )\n",
    "        message = initial_response.choices[0].message\n",
    "\n",
    "        # 3-4단계: LLM의 응답에 따라 라이브러리가 직접 도구를 실행한다.\n",
    "        if message.tool_calls:\n",
    "            tool_call = message.tool_calls[0]\n",
    "            tool_name = tool_call.function.name\n",
    "            arguments = tool_call.function.arguments\n",
    "            tool_response = self.tool_library.execute_tool(tool_name, arguments)\n",
    "\n",
    "            # 5단계: 라이브러리가 실행 결과를 다시 LLM에 보내 최종 답변을 받는다.\n",
    "            final_response = self.client.chat.completions.create(\n",
    "                model=\"gpt-4\",\n",
    "                messages=[\n",
    "                    {\"role\": \"user\", \"content\": user_message},\n",
    "                    message,\n",
    "                    {\"role\": \"tool\", \"tool_call_id\": tool_call.id, \"name\": tool_name, \"content\": str(tool_response)}\n",
    "                ]\n",
    "            )\n",
    "            return final_response.choices[0].message.content\n",
    "        return message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "kmdR7kWrkIaW",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "죄송합니다만, 현재 마이애미의 온도를 확인하는데 문제가 발생했습니다. 잠시 후에 다시 시도해주세요.\n"
     ]
    }
   ],
   "source": [
    "tool_caller = EmbeddedToolCaller(api_key)\n",
    "result = tool_caller.process_message(\"마이애미의 현재 온도는 몇 도인가요?\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "lecture",
   "language": "python",
   "name": "lecture"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
